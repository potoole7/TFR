\documentclass{article}

\usepackage[top=3cm, bottom=3cm, left=3cm,right=3cm]{geometry}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{titlesec}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{natbib} % print author's name and year when citing
\usepackage{bbm}
\usepackage{todonotes}
\usepackage{pdflscape}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{authblk}
\usepackage{pdfpages}
\usepackage{setspace} 
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{float}
\usepackage{tikz}
\usepackage[colorlinks=true,citecolor=blue, linkcolor=blue]{hyperref}
\usepackage{multirow}
\usepackage{todonotes}
\setlength{\tabcolsep}{5pt}
%%\setlength{\parindent}{0pt}
\usepackage[parfill]{parskip}
\renewcommand{\arraystretch}{1.5}

% \renewcommand\Affilfont{\itshape\footnotesize}
% \def\ci{\perp\!\!\!\perp}

% \renewcommand\Affilfont{\itshape\footnotesize}
% \linespread{1.5}

% Define a custom note command for general notes
\newcommand{\mynote}[1]{\todo[color=yellow!40,inline]{#1}}

\DeclareMathOperator*{\argmin}{arg\,min}
% \DeclareMathOperator*{\argmax}{arg\,max}

% Nature Bibliography style
% \usepackage[backend=biber,style=nature]{biblatex}
% \addbibresource{library.bib} 
\bibliographystyle{unsrtnat}

% number equations by section
\numberwithin{equation}{section}

\title{Developing clustering algorithms for conditional extremes models}
\thispagestyle{empty}
\author{Patrick O'Toole \\ SN: 239261652 \\ Supervised by Christian Rohrbeck and Jordan Richards}
% \date{July - September 2024}
\date{\today}

\begin{document}

\begin{center}
    \huge
    \vspace{1.5cm}
    \textbf{Thesis Formulation Report}

    \vspace{0.4cm}
    \huge
    Developing clustering algorithms for conditional extremes models
    
    \Large    
    \vspace{0.8cm}
    \textbf{Patrick O'Toole} \\
    Supervised by: Christian Rohrbeck and Jordan Richards \\
    % July-September 2024
    \today
    \vfill
    \includegraphics[width=7cm]{images/samba.jpg}\\
    \vspace{0.5cm}
    \includegraphics[width=5cm]{images/university-of-bath-logo.png}
    \hspace{1cm}
    \includegraphics[width=5cm]{images/UKRIlogo.png}
    \large   
    \vspace{1.5cm}
    \end{center}
\newpage

\todo{Taken from contract, edit to form proper abstract}
\begin{abstract}
  Conditional extreme value models have proven useful for analysing the joint tail behaviour of random vectors. 
  While an extensive amount of work to estimate conditional extremes models exists in multivariate and spatial applications, the prospect of clustering for models of this type has not yet been explored. 
  This project will review existing methods in the area of conditional extremes models, and develop and research ideas on how some of these models can be embedded into a clustering framework. 
  It will also involve the review of existing state-of-the-art clustering methods within extreme value analysis. 
\end{abstract}


\begin{center}
\paragraph{Responsible Research and Innovation} ~\linebreak
\todo{Make linebreak the same as abstract}
\todo{Add Responsible Research and Innovation statement}
Fill in!

\end{center}

\newpage

\tableofcontents

\newpage

Prospective ordering of sections:
\begin{enumerate}
  \item Introduction
  \item Peaks-over-threshold method for univariate extremes
  \item Conditional extremes model
  \item Clustering for extremes
  \item Motivating example
  \item Discussion and future work
\end{enumerate}
\todo{Order important, hard to think of what might be best}
\todo{Need to motivate need for dependence modelling as in H\&T 2004 and Winter 2016 papers}

\section{Introduction}\label{sec:intro}

\todo{Do this section!}

\begin{itemize}
  \item What are extremes (modelling tails of distributions where underlying stochastic process is assumed), why they are used (anywhere where we are more interested in tails of distributions). 
  \item Some simple, examples of uses in marginal estimation (and more complicated examples from reading course).
  \item Modelling of dependence between marginals required to improve return level estimation (see \cite{Winter2016}), with one such model being the conditional extremes model of \cite{Heffernan2004}. 
  \item Extremal models are notoriously difficult to fit, largely due to shape parameter, and this propagates into CE model parameters,
  \item There is a wealth of literature on clustering in extremes. However, clustering on the CE model has never been done before. 
  \item In particular, hierarchical clustering would be useful for improved parameter estimation, with a Bayesian framework further introducing priors for our parameters which are useful in extremes where there is a lack of available data. 
  \item Summarise what will be talked about in the rest of the report.
\end{itemize}

\section{Peaks-over-threshold method for univariate extremes}\label{sec:uni}

Follow other papers using GPD, like \cite{Carreau2017}. 
\begin{itemize}
  \item Peaks over threshold (reference Halkema and de Haan 1974, Pickands 1975, see Carreau 2017 for example) definition for extremes (including reference to limiting extreme value distribution $G$ from Coles 2001)
  \item Conditional CDF of GPD distribution
  \item Different tails of GPD for different signs of shape parameter
  \item Talk about different threshold selection methods, e.g.\ stability plots, including quantile regression method used in \cite{Youngman2019}.
  \item IID assumption in GPD as defined above, can model parameters as covariates, numerous methods to do this, such as using \texttt{evgam} as first introduced in \cite{Youngman2019}, and also Gaussian processes and INLA (with references).
  \item Return levels (m-observations, n-year, from \cite{Coles2001}) can be estimated from GPD parameters (derived from conditional probability and exceedance probability, as in \cite{Cooley2007} and \cite{Coles2001}). 
  \item Reference difficulty in estimating GPD and particularly $\xi$ due to lack of data and strange likelihood (following \cite{Coles2001}). 
  \item Also mention inadequacy of return level estimates with univariate methods when dependence is seen, as seen in Pacific Northwest in \cite{Winter2016}, motivating use of dependence models. 
\end{itemize}

\section{Conditional extremes model}\label{sec:ce}

Below narrative is a bit jumbled, can order better by looking at \cite{Heffernan2004}, \cite{Keef2013} and applied conditional extremes papers again. 
\todo{Anything else to add?}

\begin{itemize}
  \item Introduction to dependence modelling for extremes, following \cite{Heffernan2004} for modelling $\mathbb{P}(\bm{X} \in \bm{C})$, i.e.\ an observation which is extreme in more than one dimension, be that for multiple variables at a single location (e.g.\ rain and wind speed) or across multiple locations and/or times. 
  \item Following \cite{Tawn2018} and \cite{Heffernan2004}, introduce other methods for modelling dependence in extremes, such as max-stable, Pareto and Gaussian processes, and copulas, and their limitations, both in the restrictiveness of the type of dependence these methods can model, and their computational feasibility.
  \item Something on marginal model as piecewise ECDF and GPD, which can be fitted using any method mentioned in \ref{sec:uni}. 
  \item Starting from asymptotic motivation, define conditional extremes model as in \cite{Heffernan2004} and in applied paper as the non-parametric regression equation $Y_{-i} = a_{\mid i}(Y_{\mid i}) + \b_{\mid i}(Y_{\mid i}) Z_{\mid i}$
  \item Requires Gumbel transformation of margins to have exponential upper tail, but this gives complex form for $a$ for negative dependence, so instead following \cite{Keef2013} Laplace margins are used which have doubly exponential tails and thus have the conceptually simple $a_{\mid i} = \alpha_{\mid i}Y_{\mid i} , b = Y_{\mid i}^{\beta_{\mid i}}$, which can be interpreted as the slope and spread parameters for our semi-parametric regression line (is there a reference I can use which makes this interpretation?). 
  \item Extrapolation through MC algorithm as in \cite{Heffernan2004} (alternative in \cite{Keef2013}.
  \item Talk about diagnostics through independence of residuals and tail exceedances in the limit. 
  \item Uncertainty through bootstrap scheme,
  \item Return levels $\ldots$ (improved over univariate, as shown in \cite{Winter2016})
\end{itemize}

Can also talk about (if time/space):
\begin{itemize}
  \item Additional constraints from \cite{Keef2013} on possible values of $\alpha$ and $\beta$ to ensure stochastic ordering of $Y_j \mid Y_i = y$ for large $y$ 
  \item Can also talk about how \cite{Tawn2018} shows CE is an improvement over other methods like max-stable/Pareto processes (how much detail? Look at what other papers have done)
  \item Spatial extension in \cite{Wadsworth2018}, which has $\alpha$ which slowly decays as distance between site and some reference site increases, several choices of $\beta$ to fit different tails, and the representation of the residuals as a Gaussian process with some constraints to ensure it's value is 0 when the site in question is the same as the reference site. 
\end{itemize}

\texbf{Also have section on applications of CE model!}

\section{Clustering for extremes}\label{sec:clustering}

Mainly lit review on clustering. 
\begin{itemize}
  \item Clustering on extremes done for two reasons: improved explainability and improved parameter estimation. 
  \item First kind mainly focuses on deriving distance matrices for some metric (such as marginal GPD parameters, F-madogram, etc) and applying some classical clustering algorithm such as k-mediods. Can talk about different papers which have done this.
  \item Second kind uses hierarchical modelling and generally produces latent, ``data-driven'' group structure, methods for estimating likelihood can be split between Frequentist methods which use some flavour of EM algorithm, and Bayesian which uses MCMC, in particular \cite{Bottolo2003} and  \cite{Rohrbeck2021}, which use RJMCMC (other methods (possibly from outside extrems) include use of ``stick-breaking prior'' and latent Dirichlet allocation, reference).
  \item This kind particularly useful for extremes because of lack of data causing ``naive'' marginal $\xi$ values to have large variance (which in turn feeds into estimates of $\alpha$ and $\beta$ for CE model). 
  \item Earlier paper in this vein is \cite{Cooley2007}, but this only used domain-knowledge to fit two seperate $\xi$ values for different regions (mountainous and plains).
  \item Talk about Frequentist EM papers for GEV (\cite{Dupuis2023}) and GPD (\cite{Carreau2017})
  \item Talk about \cite{Rohrbeck2021}, how it changes RJMCMC algorithm from \cite{Bottolo2003} and uses GPD rather than PP (review both papers), how it might be an improvement on Frequentist EM methods for various reasons: 
    \begin{enumerate}
      \item Use of priors desirable where data is naturally lacking for extremal context (but may also be shunned for being opinionated?), mention use of Penalised complexity prior for $\xi$ in INLA implementation of GPD. 
      \item Inference for the \cite{Carreau2017} is quite conceptually difficult, making use of U-statistics for probability weighted moment estimators and in the GEV paper required a  consistency analysis of the QML methods used
      \item In contrast, inference for Bayesian problem could be seen as somewhat simpler, can be simply expressed through DAG with hyperpriors to enable partial pooling, can more easily limit e.g.\ $\xi$ to more reasonable values, spatial interpolation is easy (but can be made more complex), number of regions/clusters to use can be estimated with within MCMC scheme rather than e.g. cross-validation as in \cite{Carreau2017}.
      \item Any improvements in computational speed? Can talk about INLA implementation of CE and how it allows for modelling of many regions, opens up use in geostatistical context,
      \item Probabilistically defines uncertainty around parameter estimates, which is nice, compared to having to define complicated bootstrapping schemes or other methods to quantify uncertainty in Frequentist setting. 
      \item Also reference context of conditional extremes model, rather than GPD or GEV explicitely (although GPD must be estimated to then estimate CE parameters), probably more easily formulated in hierarchical Bayesian model (how?)
    \end{enumerate}
  \item Therefore, seems like a Bayesian clustering scheme for Conditional Extremes, something which has never been done before, would be desirable. Would likely largely follow \cite{Rohrbeck2021}, but wouldn't need two likelihood components as marginal estimates required to then estimate alpha parameters (or would it? Scheme could be more complicated then as you couldn't partition likelihood into decoupled components)  \mynote{Should/Do I need to go into much detail about what this would look like?}
\end{itemize}

\section{Motivating example}\label{sec:example}

\begin{enumerate}
  \item \textbf{Introduction}: Why we look at motivating example (to show how CE model works, how parameter estimates have large variance, and a simple, likely incorrect clustering procedure can be performed on the outputted parameters/regression lines) \todo{Fill in more}
  \item \textbf{Data}: Weekly Winter precipitation sum and daily wind speed maxima for Ireland from 1990 to 2020 inclusive, 
    % ignoring weeks with no rain, 
    as in \cite{Vignotto2021}. Include single exploratory plot to showcase data (left plot could have locations of weather sites, right could have rainfall plotted against wind speed for a given site).
  % \todo{Test removing weeks with no rain versus keeping them, does this result in larger thresholds through quantile regression being taken?}
  \begin{itemize}
    \item Precipitation data from Met Eireann, wind speed data from ERA5 reanalysis, reference accordingly (also map from 
  \end{itemize}
  \item \textbf{Model}:
    \begin{enumerate}
      \item \textbf{Marginal model}: uses \texttt{evgam} to estimate $\sigma, \xi$ at each location smoothing both over space (can take from ITT2 report) for GPDs fitted to precipitation and wind speed, respectively.
      \begin{itemize}
        \item Also uses method from \cite{Youngman2019} whereby location-specific thresholds are defined as fixed quantiles and estimated by quantile regression.
      \end{itemize}
      \item \textbf{Dependence model} uses \texttt{texmex} to fit conditional extremes model on top of marginal models to estimate $\alpha, \beta$ for rain $\mid$ wind speed and vice versa for each location. 
        Vanilla CE used for simplicity of implementation for this motivating example. 
      % \item \textbf{Clustering}: Two (likely incorrect/significantly flawed) simple clustering algorithms:
      \item \textbf{Clustering}: (likely incorrect/significantly flawed or overly simplistic, which is fine as it motivates further work) simple clustering algorithms:
        \begin{itemize}
        % \begin{enumerate}
        % \item Euclidean distance between centroids for each location defined as
        % \[
        %   (\alpha_{rain}, \beta_{rain}, \alpha_{wind speed}, \beta_{wind speed}), 
        % \] 
        % perform k-mediods clustering on distance matrix, use elbow plot to choose number of clusters \todo{Should I even include this? Very exploratory!}
          \item Following similar method to \cite{Vignotto2021}, at each location have Laplace distributed fitted regression lines $Y_{-i} = \alpha_{\mid i}(Y_{\mid i}) + Y_{\mid i}^{\beta_{\mid i}} Z_{\mid i}$, take excesses over high quantile (same as in dependence modelling) (no need for their risk function), partition into subsets of points which are extreme for one of or both rainfall and wind speeds, calculate KL divergence between locations as in paper to get distance matrix, perform k-mediods on this (gives centroid to each cluster which corresponds to an actual data point). Choose optimal number of clusters using silhouette method. 
        % \end{enumerate}
        \end{itemize}
      \item \textbf{Refitting}: Refit model using data from all cluster members centred at cluster centroid, see if this reduces variance in estimates for $\xi$ (could leave $\sigma$ estimated for each individual site) \todo{Still to do!}
    \end{enumerate}
  \item \textbf{Results}: 
    \begin{enumerate}
      \item \textbf{Marginals}: Show maps of $\sigma$ and $\xi$ for both rain and wind speed, $\ldots$ (what else?)
      \item Possibly show uncertainty in $\xi$ estimates
      \item \textbf{Dependence}:
        \begin{enumerate}
          \item Show diagnostic and quantile plots for CE for some location(s),
          \item Show bootstrapped $\alpha$ and $\beta$ values for rain $\mid$ wind speed and wind speed $\mid$ rain for different thresholds, motivating choice of CE threshold at 70th quantile, and fixing $\beta$ at 0.1 so that all variability is in $\alpha$ (also makes interpretation easier, and need for this further highlights need for better parameter estimation through grouping and/or some hierarchical model). 
          \item Bootstrapped values for $\xi$ (under vanilla \texttt{texmex} marginal estimates, rather than \texttt{evgam}) and $\alpha$ show that uncertainty high in both, even when fixing $\beta$. 
          \item Maps of $\alpha$ values conditioning on rain and windspeed, possibly cross-hatch where bootstrapped $\alpha$ values have 95\% CI which intersects 0. 
          \item Plot of $\alpha$ values versus longitude and latitude (possibly coloured by distance to coast), showing how space is main driver in difference (unsurprising as used as only covariate in marginal \texttt{evgam} model). 
        \end{enumerate}
      \item \textbf{Clustering}
        \begin{enumerate}
          \item Plot Laplace regression lines with quantiles and separation of bivariate space into regions where one or both variables are extreme, as in \cite{Vignotto2021}. 
          \item Show map of cluster membership, possibly under multiple $K$ values. 
        \end{enumerate} 
      \item \textbf{Refitting}
        \begin{enumerate}
          \item New bootstrapped values for $\xi$ and $\alpha$, hopefully see reduction in variance, but likely not much as our clustering hasn't been very principled and is merely used as a motivating example. 
          \item New maps of $\alpha$ values, with points coloured by cluster membership and cluster centroids denoted with different shape. 
        \end{enumerate}
    \end{enumerate}
  \item \textbf{Discussion}:
    \begin{itemize}
      \item Marginal and dependence parameter estimates show how $\xi$ and $sigma$ vary over space for Ireland, with the north-west having the most extreme weather conditions. 
      \item Uncertainty in $\xi$ values shown in bootstrapping motivates need for clustering to reduce variance in estimates.
      \item Clustering not very principled and done more for explainability purposes than improving parameter estimation, but can comment on how it does at this task, and if this is likely done poorly than this motivates further work. 
    \end{itemize}
\end{enumerate}
\section{Discussion and future work}\label{sec:discussion}

Summary of report:
\begin{itemize}
  \begin{enumerate}
    \item Introduced extremes, why they are important, why dependence modelling is important,
    \item Showed how univariate extremes can be modelled using GPD,
    \item Introduced dependence modelling and the conditional extremes model, why it's an improvement over previous models, where it may be susceptible to uncertainty in $\xi$ estimates and some previous applications of the model.
    \item Reviewed clustering methods for extremes, shown examples of both types of clustering, explanatory clustering likely not applicable in this context, but hierarchical Bayesian clustering methods likely to be useful,
    \item Presented a motivating example which shows how the conditional extremes model can be fit, how parameter estimates can have very large variance, how clustering could be done on these parameters, and how simple methods are inadequate, leading to the need for more involved research into this topic. 
  \end{enumerate}
\end{itemize}

Future work:
\begin{itemize}
  \item Try Bayesian clustering approach similar to \cite{Rohrbeck2021}, will involve deriving likelihood for CE model and priors for parameter values. 
  \item Later, can extend the model to spatial CE from \cite{Tawn2018}.
\end{itemize}

\section{Code availability}

\begin{itemize}
  \item Code for analysis available at \url{https://github.com/potoole7/TFR}.
  \item Fork of \texttt{texmex} package available at \url{http://github.com/potoole7/texmex}, adds functionality to fix $\beta$ values and only estimate $\alpha$. \todo{anything else added?}
\end{itemize}

\newpage
\bibliography{library}

\end{document}
